\begin{table}[ht]
	\caption{The End-to-End performance using different reranking models after instruction extraction with grounding. Results marked with * are statistical significantly higher than the baseline. TMLP is short for Transformer-MLP model, LR for the logistic regression model, $F_4$ is the instructions completion degree. Models marked with "Google rank" use the Google rank to determine the relative order of two terms when they have the same reranking scoring.}
	\label{tab:reranking_end_to_end_performance}
	\begin{tabular}{c|cccc}
			\textbf{Model}                             & \textbf{MRR} & \textbf{P@1} & \textbf{P@5} & \textbf{NDCG@5} \\
			\toprule
			Baseline: Google            & 0.1782       & 0.1138       & 0.0850       & 0.1692          \\
			$F_4$-based rank($F_4$)     & 0.2107       & 0.1737       & 0.0946       & 0.1971          \\ %filter_out_by_extraction: 7 out of 167 queries
			$F_4$-based rule($F_4 = 1$) & 0.1523       & 0.1317       & 0.0778       & 0.1432          \\ %ablation study
			LR                          & 0.1943       & 0.1677       & 0.0766       & 0.1943          \\
			NeuralNDCG + TMLP           & 0.2031       & 0.1856       & 0.0790       & 0.2033          \\
			LambdaLoss + TMLP           & 0.2133       & 0.2036       & 0.0814       & 0.2122          \\
			Optimal: Ground truth       & 0.3353       & 0.3353       & 0.1365       & 0.3353          \\
	\end{tabular}
\end{table}